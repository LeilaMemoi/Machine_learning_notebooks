{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LAB SESSION 2 - Bagging and Random Forests**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: in all this project, use **the value 0** when you need to choose a value for a random state*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 1: comparison between random forests and bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We work with the [Urban Land Cover data base](https://archive.ics.uci.edu/ml/datasets/Urban+Land+Cover). The data are used for automated mapping of urban land cover (trees, grass, soil, concrete, asphalt, buildings, etc.) in satellite or aerial imagery. Nine types of urban land cover are considered and multi-scale spectral, size, shape, and texture information are used for classification. The data consists in a train set and a test set. **The goal is to predict the urban land cover (the variable named `class`) based on the multi-scale spectral, size, shape, and texture information. It is then a classification problem. We will use the overall accuracy (1-misclassification rate) as performance criterion**. Note that other preformnce criterion exist for classification problem such as specificity, sensitivity, F-score, etc.\n",
    "\n",
    "Before to start, we: \n",
    " 1) load the data and perform a briel descriptive analysis of them;\n",
    " 2) select the variables that we will use in the exercise, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "import pandas as pd # data analysis\n",
    "ulc_train = pd.read_csv(\"ULC_training.csv\") \n",
    "ulc_test = pd.read_csv(\"ULC_testing.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(168, 148)\n",
      "(507, 148)\n"
     ]
    }
   ],
   "source": [
    "# Display the dimension\n",
    "print(ulc_train.shape)\n",
    "print(ulc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>BrdIndx</th>\n",
       "      <th>Area</th>\n",
       "      <th>Round</th>\n",
       "      <th>Bright</th>\n",
       "      <th>Compact</th>\n",
       "      <th>ShpIndx</th>\n",
       "      <th>Mean_G</th>\n",
       "      <th>Mean_R</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_NIR_140</th>\n",
       "      <th>LW_140</th>\n",
       "      <th>GLCM1_140</th>\n",
       "      <th>Rect_140</th>\n",
       "      <th>GLCM2_140</th>\n",
       "      <th>Dens_140</th>\n",
       "      <th>Assym_140</th>\n",
       "      <th>NDVI_140</th>\n",
       "      <th>BordLngth_140</th>\n",
       "      <th>GLCM3_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>car</td>\n",
       "      <td>1.27</td>\n",
       "      <td>91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>231.38</td>\n",
       "      <td>1.39</td>\n",
       "      <td>1.47</td>\n",
       "      <td>207.92</td>\n",
       "      <td>241.74</td>\n",
       "      <td>244.48</td>\n",
       "      <td>...</td>\n",
       "      <td>26.18</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.85</td>\n",
       "      <td>6.29</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.70</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>56</td>\n",
       "      <td>3806.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.36</td>\n",
       "      <td>241</td>\n",
       "      <td>1.56</td>\n",
       "      <td>216.15</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.51</td>\n",
       "      <td>187.85</td>\n",
       "      <td>229.39</td>\n",
       "      <td>231.20</td>\n",
       "      <td>...</td>\n",
       "      <td>22.29</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.42</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1746</td>\n",
       "      <td>1450.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.12</td>\n",
       "      <td>266</td>\n",
       "      <td>1.47</td>\n",
       "      <td>232.18</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.21</td>\n",
       "      <td>206.54</td>\n",
       "      <td>244.22</td>\n",
       "      <td>245.79</td>\n",
       "      <td>...</td>\n",
       "      <td>15.59</td>\n",
       "      <td>2.19</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.24</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.81</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>566</td>\n",
       "      <td>1094.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.42</td>\n",
       "      <td>399</td>\n",
       "      <td>1.28</td>\n",
       "      <td>230.40</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.73</td>\n",
       "      <td>204.60</td>\n",
       "      <td>243.27</td>\n",
       "      <td>243.32</td>\n",
       "      <td>...</td>\n",
       "      <td>13.51</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.74</td>\n",
       "      <td>7.44</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>1178</td>\n",
       "      <td>1125.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>concrete</td>\n",
       "      <td>2.15</td>\n",
       "      <td>944</td>\n",
       "      <td>1.73</td>\n",
       "      <td>193.18</td>\n",
       "      <td>2.28</td>\n",
       "      <td>4.10</td>\n",
       "      <td>165.98</td>\n",
       "      <td>205.55</td>\n",
       "      <td>208.00</td>\n",
       "      <td>...</td>\n",
       "      <td>15.65</td>\n",
       "      <td>50.08</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.49</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>6232</td>\n",
       "      <td>1146.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  BrdIndx  Area  Round  Bright  Compact  ShpIndx  Mean_G  Mean_R  \\\n",
       "0       car      1.27    91   0.97  231.38     1.39     1.47  207.92  241.74   \n",
       "1  concrete      2.36   241   1.56  216.15     2.46     2.51  187.85  229.39   \n",
       "2  concrete      2.12   266   1.47  232.18     2.07     2.21  206.54  244.22   \n",
       "3  concrete      2.42   399   1.28  230.40     2.49     2.73  204.60  243.27   \n",
       "4  concrete      2.15   944   1.73  193.18     2.28     4.10  165.98  205.55   \n",
       "\n",
       "   Mean_NIR  ...  SD_NIR_140  LW_140  GLCM1_140  Rect_140  GLCM2_140  \\\n",
       "0    244.48  ...       26.18    2.00       0.50      0.85       6.29   \n",
       "1    231.20  ...       22.29    2.25       0.79      0.55       8.42   \n",
       "2    245.79  ...       15.59    2.19       0.76      0.74       7.24   \n",
       "3    243.32  ...       13.51    3.34       0.82      0.74       7.44   \n",
       "4    208.00  ...       15.65   50.08       0.85      0.49       8.15   \n",
       "\n",
       "   Dens_140  Assym_140  NDVI_140  BordLngth_140  GLCM3_140  \n",
       "0      1.67       0.70     -0.08             56    3806.36  \n",
       "1      1.38       0.81     -0.09           1746    1450.14  \n",
       "2      1.68       0.81     -0.07            566    1094.04  \n",
       "3      1.36       0.92     -0.09           1178    1125.38  \n",
       "4      0.23       1.00     -0.08           6232    1146.38  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a first quick look at the datasets and display the dimension\n",
    "ulc_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>BrdIndx</th>\n",
       "      <th>Area</th>\n",
       "      <th>Round</th>\n",
       "      <th>Bright</th>\n",
       "      <th>Compact</th>\n",
       "      <th>ShpIndx</th>\n",
       "      <th>Mean_G</th>\n",
       "      <th>Mean_R</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_NIR_140</th>\n",
       "      <th>LW_140</th>\n",
       "      <th>GLCM1_140</th>\n",
       "      <th>Rect_140</th>\n",
       "      <th>GLCM2_140</th>\n",
       "      <th>Dens_140</th>\n",
       "      <th>Assym_140</th>\n",
       "      <th>NDVI_140</th>\n",
       "      <th>BordLngth_140</th>\n",
       "      <th>GLCM3_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>concrete</td>\n",
       "      <td>1.32</td>\n",
       "      <td>131</td>\n",
       "      <td>0.81</td>\n",
       "      <td>222.74</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.18</td>\n",
       "      <td>192.94</td>\n",
       "      <td>235.11</td>\n",
       "      <td>240.15</td>\n",
       "      <td>...</td>\n",
       "      <td>31.15</td>\n",
       "      <td>5.04</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.58</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.98</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1512</td>\n",
       "      <td>1287.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shadow</td>\n",
       "      <td>1.59</td>\n",
       "      <td>864</td>\n",
       "      <td>0.94</td>\n",
       "      <td>47.56</td>\n",
       "      <td>1.41</td>\n",
       "      <td>1.87</td>\n",
       "      <td>36.82</td>\n",
       "      <td>48.78</td>\n",
       "      <td>57.09</td>\n",
       "      <td>...</td>\n",
       "      <td>12.01</td>\n",
       "      <td>3.70</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.96</td>\n",
       "      <td>7.01</td>\n",
       "      <td>1.69</td>\n",
       "      <td>0.86</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>196</td>\n",
       "      <td>2659.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>shadow</td>\n",
       "      <td>1.41</td>\n",
       "      <td>409</td>\n",
       "      <td>1.00</td>\n",
       "      <td>51.38</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1.53</td>\n",
       "      <td>41.72</td>\n",
       "      <td>51.96</td>\n",
       "      <td>60.48</td>\n",
       "      <td>...</td>\n",
       "      <td>18.75</td>\n",
       "      <td>3.09</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.63</td>\n",
       "      <td>8.32</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1198</td>\n",
       "      <td>720.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tree</td>\n",
       "      <td>2.58</td>\n",
       "      <td>187</td>\n",
       "      <td>1.91</td>\n",
       "      <td>70.08</td>\n",
       "      <td>3.41</td>\n",
       "      <td>3.11</td>\n",
       "      <td>93.13</td>\n",
       "      <td>55.20</td>\n",
       "      <td>61.92</td>\n",
       "      <td>...</td>\n",
       "      <td>27.67</td>\n",
       "      <td>6.33</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.70</td>\n",
       "      <td>8.56</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.20</td>\n",
       "      <td>524</td>\n",
       "      <td>891.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asphalt</td>\n",
       "      <td>2.60</td>\n",
       "      <td>116</td>\n",
       "      <td>2.05</td>\n",
       "      <td>89.57</td>\n",
       "      <td>3.06</td>\n",
       "      <td>3.02</td>\n",
       "      <td>73.17</td>\n",
       "      <td>94.89</td>\n",
       "      <td>100.64</td>\n",
       "      <td>...</td>\n",
       "      <td>32.05</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8.62</td>\n",
       "      <td>2.08</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>496</td>\n",
       "      <td>1194.76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  BrdIndx  Area  Round  Bright  Compact  ShpIndx  Mean_G  Mean_R  \\\n",
       "0  concrete      1.32   131   0.81  222.74     1.66     2.18  192.94  235.11   \n",
       "1    shadow      1.59   864   0.94   47.56     1.41     1.87   36.82   48.78   \n",
       "2    shadow      1.41   409   1.00   51.38     1.37     1.53   41.72   51.96   \n",
       "3      tree      2.58   187   1.91   70.08     3.41     3.11   93.13   55.20   \n",
       "4   asphalt      2.60   116   2.05   89.57     3.06     3.02   73.17   94.89   \n",
       "\n",
       "   Mean_NIR  ...  SD_NIR_140  LW_140  GLCM1_140  Rect_140  GLCM2_140  \\\n",
       "0    240.15  ...       31.15    5.04       0.80      0.58       8.56   \n",
       "1     57.09  ...       12.01    3.70       0.52      0.96       7.01   \n",
       "2     60.48  ...       18.75    3.09       0.90      0.63       8.32   \n",
       "3     61.92  ...       27.67    6.33       0.89      0.70       8.56   \n",
       "4    100.64  ...       32.05    1.01       0.83      0.75       8.62   \n",
       "\n",
       "   Dens_140  Assym_140  NDVI_140  BordLngth_140  GLCM3_140  \n",
       "0      0.82       0.98     -0.10           1512    1287.52  \n",
       "1      1.69       0.86     -0.14            196    2659.74  \n",
       "2      1.38       0.84      0.10           1198     720.38  \n",
       "3      1.10       0.96      0.20            524     891.36  \n",
       "4      2.08       0.08     -0.10            496    1194.76  \n",
       "\n",
       "[5 rows x 148 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulc_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>BrdIndx</th>\n",
       "      <th>Area</th>\n",
       "      <th>Round</th>\n",
       "      <th>Bright</th>\n",
       "      <th>Compact</th>\n",
       "      <th>ShpIndx</th>\n",
       "      <th>Mean_G</th>\n",
       "      <th>Mean_R</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_NIR_140</th>\n",
       "      <th>LW_140</th>\n",
       "      <th>GLCM1_140</th>\n",
       "      <th>Rect_140</th>\n",
       "      <th>GLCM2_140</th>\n",
       "      <th>Dens_140</th>\n",
       "      <th>Assym_140</th>\n",
       "      <th>NDVI_140</th>\n",
       "      <th>BordLngth_140</th>\n",
       "      <th>GLCM3_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>168</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>168.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>grass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.008512</td>\n",
       "      <td>565.869048</td>\n",
       "      <td>1.132976</td>\n",
       "      <td>165.569821</td>\n",
       "      <td>2.077679</td>\n",
       "      <td>2.229881</td>\n",
       "      <td>161.577083</td>\n",
       "      <td>163.672440</td>\n",
       "      <td>171.459226</td>\n",
       "      <td>...</td>\n",
       "      <td>23.769881</td>\n",
       "      <td>3.098274</td>\n",
       "      <td>0.796488</td>\n",
       "      <td>0.665000</td>\n",
       "      <td>7.795536</td>\n",
       "      <td>1.594405</td>\n",
       "      <td>0.615357</td>\n",
       "      <td>0.014583</td>\n",
       "      <td>983.309524</td>\n",
       "      <td>1275.292917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.634807</td>\n",
       "      <td>679.852886</td>\n",
       "      <td>0.489150</td>\n",
       "      <td>61.883993</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.703572</td>\n",
       "      <td>63.407201</td>\n",
       "      <td>71.306748</td>\n",
       "      <td>67.973969</td>\n",
       "      <td>...</td>\n",
       "      <td>12.836522</td>\n",
       "      <td>6.101883</td>\n",
       "      <td>0.103930</td>\n",
       "      <td>0.179086</td>\n",
       "      <td>0.670491</td>\n",
       "      <td>0.460627</td>\n",
       "      <td>0.239900</td>\n",
       "      <td>0.153677</td>\n",
       "      <td>880.013745</td>\n",
       "      <td>603.658611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>37.670000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.060000</td>\n",
       "      <td>30.680000</td>\n",
       "      <td>32.210000</td>\n",
       "      <td>40.120000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.330000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>6.290000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.360000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>336.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.537500</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>133.977500</td>\n",
       "      <td>1.547500</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>91.040000</td>\n",
       "      <td>101.187500</td>\n",
       "      <td>120.165000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.965000</td>\n",
       "      <td>1.395000</td>\n",
       "      <td>0.757500</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>7.357500</td>\n",
       "      <td>1.325000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>817.405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>1.085000</td>\n",
       "      <td>164.485000</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>2.130000</td>\n",
       "      <td>187.560000</td>\n",
       "      <td>160.615000</td>\n",
       "      <td>178.345000</td>\n",
       "      <td>...</td>\n",
       "      <td>21.135000</td>\n",
       "      <td>1.740000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>7.790000</td>\n",
       "      <td>1.660000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>-0.040000</td>\n",
       "      <td>776.000000</td>\n",
       "      <td>1187.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.375000</td>\n",
       "      <td>667.000000</td>\n",
       "      <td>1.410000</td>\n",
       "      <td>221.895000</td>\n",
       "      <td>2.460000</td>\n",
       "      <td>2.680000</td>\n",
       "      <td>210.940000</td>\n",
       "      <td>234.815000</td>\n",
       "      <td>236.002500</td>\n",
       "      <td>...</td>\n",
       "      <td>29.957500</td>\n",
       "      <td>2.285000</td>\n",
       "      <td>0.870000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>8.260000</td>\n",
       "      <td>1.945000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1412.500000</td>\n",
       "      <td>1588.427500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.190000</td>\n",
       "      <td>3659.000000</td>\n",
       "      <td>2.890000</td>\n",
       "      <td>244.740000</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>246.350000</td>\n",
       "      <td>253.080000</td>\n",
       "      <td>253.320000</td>\n",
       "      <td>...</td>\n",
       "      <td>60.020000</td>\n",
       "      <td>51.540000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>9.340000</td>\n",
       "      <td>2.340000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>6232.000000</td>\n",
       "      <td>3806.360000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         class     BrdIndx         Area       Round      Bright     Compact  \\\n",
       "count      168  168.000000   168.000000  168.000000  168.000000  168.000000   \n",
       "unique       9         NaN          NaN         NaN         NaN         NaN   \n",
       "top     grass          NaN          NaN         NaN         NaN         NaN   \n",
       "freq        29         NaN          NaN         NaN         NaN         NaN   \n",
       "mean       NaN    2.008512   565.869048    1.132976  165.569821    2.077679   \n",
       "std        NaN    0.634807   679.852886    0.489150   61.883993    0.699600   \n",
       "min        NaN    1.000000    10.000000    0.020000   37.670000    1.000000   \n",
       "25%        NaN    1.537500   178.000000    0.787500  133.977500    1.547500   \n",
       "50%        NaN    1.920000   315.000000    1.085000  164.485000    1.940000   \n",
       "75%        NaN    2.375000   667.000000    1.410000  221.895000    2.460000   \n",
       "max        NaN    4.190000  3659.000000    2.890000  244.740000    4.700000   \n",
       "\n",
       "           ShpIndx      Mean_G      Mean_R    Mean_NIR  ...  SD_NIR_140  \\\n",
       "count   168.000000  168.000000  168.000000  168.000000  ...  168.000000   \n",
       "unique         NaN         NaN         NaN         NaN  ...         NaN   \n",
       "top            NaN         NaN         NaN         NaN  ...         NaN   \n",
       "freq           NaN         NaN         NaN         NaN  ...         NaN   \n",
       "mean      2.229881  161.577083  163.672440  171.459226  ...   23.769881   \n",
       "std       0.703572   63.407201   71.306748   67.973969  ...   12.836522   \n",
       "min       1.060000   30.680000   32.210000   40.120000  ...    4.020000   \n",
       "25%       1.700000   91.040000  101.187500  120.165000  ...   13.965000   \n",
       "50%       2.130000  187.560000  160.615000  178.345000  ...   21.135000   \n",
       "75%       2.680000  210.940000  234.815000  236.002500  ...   29.957500   \n",
       "max       4.300000  246.350000  253.080000  253.320000  ...   60.020000   \n",
       "\n",
       "            LW_140   GLCM1_140    Rect_140   GLCM2_140    Dens_140  \\\n",
       "count   168.000000  168.000000  168.000000  168.000000  168.000000   \n",
       "unique         NaN         NaN         NaN         NaN         NaN   \n",
       "top            NaN         NaN         NaN         NaN         NaN   \n",
       "freq           NaN         NaN         NaN         NaN         NaN   \n",
       "mean      3.098274    0.796488    0.665000    7.795536    1.594405   \n",
       "std       6.101883    0.103930    0.179086    0.670491    0.460627   \n",
       "min       1.000000    0.330000    0.240000    6.290000    0.230000   \n",
       "25%       1.395000    0.757500    0.560000    7.357500    1.325000   \n",
       "50%       1.740000    0.810000    0.690000    7.790000    1.660000   \n",
       "75%       2.285000    0.870000    0.810000    8.260000    1.945000   \n",
       "max      51.540000    0.950000    0.980000    9.340000    2.340000   \n",
       "\n",
       "         Assym_140    NDVI_140  BordLngth_140    GLCM3_140  \n",
       "count   168.000000  168.000000     168.000000   168.000000  \n",
       "unique         NaN         NaN            NaN          NaN  \n",
       "top            NaN         NaN            NaN          NaN  \n",
       "freq           NaN         NaN            NaN          NaN  \n",
       "mean      0.615357    0.014583     983.309524  1275.292917  \n",
       "std       0.239900    0.153677     880.013745   603.658611  \n",
       "min       0.070000   -0.360000      56.000000   336.730000  \n",
       "25%       0.460000   -0.080000     320.000000   817.405000  \n",
       "50%       0.620000   -0.040000     776.000000  1187.025000  \n",
       "75%       0.810000    0.120000    1412.500000  1588.427500  \n",
       "max       1.000000    0.350000    6232.000000  3806.360000  \n",
       "\n",
       "[11 rows x 148 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display a statistic summary for the numerical variables\n",
    "ulc_train.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>BrdIndx</th>\n",
       "      <th>Area</th>\n",
       "      <th>Round</th>\n",
       "      <th>Bright</th>\n",
       "      <th>Compact</th>\n",
       "      <th>ShpIndx</th>\n",
       "      <th>Mean_G</th>\n",
       "      <th>Mean_R</th>\n",
       "      <th>Mean_NIR</th>\n",
       "      <th>...</th>\n",
       "      <th>SD_NIR_140</th>\n",
       "      <th>LW_140</th>\n",
       "      <th>GLCM1_140</th>\n",
       "      <th>Rect_140</th>\n",
       "      <th>GLCM2_140</th>\n",
       "      <th>Dens_140</th>\n",
       "      <th>Assym_140</th>\n",
       "      <th>NDVI_140</th>\n",
       "      <th>BordLngth_140</th>\n",
       "      <th>GLCM3_140</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>507</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "      <td>507.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>building</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.025720</td>\n",
       "      <td>562.504931</td>\n",
       "      <td>1.237574</td>\n",
       "      <td>165.612939</td>\n",
       "      <td>2.187081</td>\n",
       "      <td>2.277318</td>\n",
       "      <td>166.290355</td>\n",
       "      <td>162.291953</td>\n",
       "      <td>168.256667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.601144</td>\n",
       "      <td>2.931657</td>\n",
       "      <td>0.817712</td>\n",
       "      <td>0.597732</td>\n",
       "      <td>8.048698</td>\n",
       "      <td>1.455838</td>\n",
       "      <td>0.653905</td>\n",
       "      <td>0.027436</td>\n",
       "      <td>1398.706114</td>\n",
       "      <td>1101.998185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619254</td>\n",
       "      <td>698.655240</td>\n",
       "      <td>0.561988</td>\n",
       "      <td>63.230806</td>\n",
       "      <td>0.874054</td>\n",
       "      <td>0.718441</td>\n",
       "      <td>59.217648</td>\n",
       "      <td>73.455101</td>\n",
       "      <td>69.702475</td>\n",
       "      <td>...</td>\n",
       "      <td>12.203441</td>\n",
       "      <td>4.942887</td>\n",
       "      <td>0.106007</td>\n",
       "      <td>0.197505</td>\n",
       "      <td>0.787912</td>\n",
       "      <td>0.451781</td>\n",
       "      <td>0.251287</td>\n",
       "      <td>0.133834</td>\n",
       "      <td>1097.323462</td>\n",
       "      <td>533.927869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.850000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.040000</td>\n",
       "      <td>22.910000</td>\n",
       "      <td>26.520000</td>\n",
       "      <td>31.110000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.650000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>5.690000</td>\n",
       "      <td>0.240000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>-0.360000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>211.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.580000</td>\n",
       "      <td>159.000000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>127.485000</td>\n",
       "      <td>1.650000</td>\n",
       "      <td>1.715000</td>\n",
       "      <td>146.460000</td>\n",
       "      <td>97.585000</td>\n",
       "      <td>111.715000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.485000</td>\n",
       "      <td>1.375000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>7.370000</td>\n",
       "      <td>1.160000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>-0.080000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>726.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>323.000000</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>170.650000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>189.630000</td>\n",
       "      <td>158.280000</td>\n",
       "      <td>167.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.380000</td>\n",
       "      <td>1.920000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.610000</td>\n",
       "      <td>8.020000</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>1148.000000</td>\n",
       "      <td>1011.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.380000</td>\n",
       "      <td>681.500000</td>\n",
       "      <td>1.565000</td>\n",
       "      <td>224.825000</td>\n",
       "      <td>2.490000</td>\n",
       "      <td>2.675000</td>\n",
       "      <td>206.780000</td>\n",
       "      <td>237.375000</td>\n",
       "      <td>238.480000</td>\n",
       "      <td>...</td>\n",
       "      <td>33.825000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>8.750000</td>\n",
       "      <td>1.775000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.145000</td>\n",
       "      <td>1874.000000</td>\n",
       "      <td>1335.640000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.530000</td>\n",
       "      <td>5767.000000</td>\n",
       "      <td>3.520000</td>\n",
       "      <td>245.870000</td>\n",
       "      <td>8.070000</td>\n",
       "      <td>5.410000</td>\n",
       "      <td>239.370000</td>\n",
       "      <td>253.610000</td>\n",
       "      <td>253.630000</td>\n",
       "      <td>...</td>\n",
       "      <td>61.340000</td>\n",
       "      <td>64.700000</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.570000</td>\n",
       "      <td>2.410000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.370000</td>\n",
       "      <td>8896.000000</td>\n",
       "      <td>3619.280000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            class     BrdIndx         Area       Round      Bright  \\\n",
       "count         507  507.000000   507.000000  507.000000  507.000000   \n",
       "unique          9         NaN          NaN         NaN         NaN   \n",
       "top     building          NaN          NaN         NaN         NaN   \n",
       "freq           97         NaN          NaN         NaN         NaN   \n",
       "mean          NaN    2.025720   562.504931    1.237574  165.612939   \n",
       "std           NaN    0.619254   698.655240    0.561988   63.230806   \n",
       "min           NaN    1.000000    22.000000    0.000000   26.850000   \n",
       "25%           NaN    1.580000   159.000000    0.840000  127.485000   \n",
       "50%           NaN    1.950000   323.000000    1.210000  170.650000   \n",
       "75%           NaN    2.380000   681.500000    1.565000  224.825000   \n",
       "max           NaN    4.530000  5767.000000    3.520000  245.870000   \n",
       "\n",
       "           Compact     ShpIndx      Mean_G      Mean_R    Mean_NIR  ...  \\\n",
       "count   507.000000  507.000000  507.000000  507.000000  507.000000  ...   \n",
       "unique         NaN         NaN         NaN         NaN         NaN  ...   \n",
       "top            NaN         NaN         NaN         NaN         NaN  ...   \n",
       "freq           NaN         NaN         NaN         NaN         NaN  ...   \n",
       "mean      2.187081    2.277318  166.290355  162.291953  168.256667  ...   \n",
       "std       0.874054    0.718441   59.217648   73.455101   69.702475  ...   \n",
       "min       1.000000    1.040000   22.910000   26.520000   31.110000  ...   \n",
       "25%       1.650000    1.715000  146.460000   97.585000  111.715000  ...   \n",
       "50%       2.000000    2.180000  189.630000  158.280000  167.750000  ...   \n",
       "75%       2.490000    2.675000  206.780000  237.375000  238.480000  ...   \n",
       "max       8.070000    5.410000  239.370000  253.610000  253.630000  ...   \n",
       "\n",
       "        SD_NIR_140      LW_140   GLCM1_140    Rect_140   GLCM2_140  \\\n",
       "count   507.000000  507.000000  507.000000  507.000000  507.000000   \n",
       "unique         NaN         NaN         NaN         NaN         NaN   \n",
       "top            NaN         NaN         NaN         NaN         NaN   \n",
       "freq           NaN         NaN         NaN         NaN         NaN   \n",
       "mean     24.601144    2.931657    0.817712    0.597732    8.048698   \n",
       "std      12.203441    4.942887    0.106007    0.197505    0.787912   \n",
       "min       2.650000    1.000000    0.200000    0.100000    5.690000   \n",
       "25%      14.485000    1.375000    0.770000    0.455000    7.370000   \n",
       "50%      22.380000    1.920000    0.840000    0.610000    8.020000   \n",
       "75%      33.825000    2.800000    0.890000    0.760000    8.750000   \n",
       "max      61.340000   64.700000    0.970000    1.000000    9.570000   \n",
       "\n",
       "          Dens_140   Assym_140    NDVI_140  BordLngth_140    GLCM3_140  \n",
       "count   507.000000  507.000000  507.000000     507.000000   507.000000  \n",
       "unique         NaN         NaN         NaN            NaN          NaN  \n",
       "top            NaN         NaN         NaN            NaN          NaN  \n",
       "freq           NaN         NaN         NaN            NaN          NaN  \n",
       "mean      1.455838    0.653905    0.027436    1398.706114  1101.998185  \n",
       "std       0.451781    0.251287    0.133834    1097.323462   533.927869  \n",
       "min       0.240000    0.030000   -0.360000      34.000000   211.270000  \n",
       "25%       1.160000    0.470000   -0.080000     601.000000   726.745000  \n",
       "50%       1.440000    0.710000   -0.020000    1148.000000  1011.230000  \n",
       "75%       1.775000    0.860000    0.145000    1874.000000  1335.640000  \n",
       "max       2.410000    1.000000    0.370000    8896.000000  3619.280000  \n",
       "\n",
       "[11 rows x 148 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulc_test.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "grass        29\n",
       "building     25\n",
       "concrete     23\n",
       "tree         17\n",
       "shadow       16\n",
       "car          15\n",
       "pool         15\n",
       "asphalt      14\n",
       "soil         14\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Display the distribution of the target variable in the two datasets\n",
    "ulc_train['class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "building     97\n",
       "concrete     93\n",
       "tree         89\n",
       "grass        83\n",
       "shadow       45\n",
       "asphalt      45\n",
       "car          21\n",
       "soil         20\n",
       "pool         14\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ulc_test['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "['BrdIndx', 'Area', 'Round', 'Bright', 'Compact', 'ShpIndx', 'Mean_G', 'Mean_R', 'Mean_NIR', 'SD_G', 'SD_R', 'SD_NIR', 'LW', 'GLCM1', 'Rect', 'GLCM2', 'Dens', 'Assym', 'NDVI', 'BordLngth', 'GLCM3', 'BrdIndx_40', 'Area_40', 'Round_40', 'Bright_40', 'Compact_40', 'ShpIndx_40', 'Mean_G_40', 'Mean_R_40', 'Mean_NIR_40', 'SD_G_40', 'SD_R_40', 'SD_NIR_40', 'LW_40', 'GLCM1_40', 'Rect_40', 'GLCM2_40', 'Dens_40', 'Assym_40', 'NDVI_40', 'BordLngth_40', 'GLCM3_40', 'BrdIndx_60', 'Area_60', 'Round_60', 'Bright_60', 'Compact_60', 'ShpIndx_60', 'Mean_G_60', 'Mean_R_60', 'Mean_NIR_60', 'SD_G_60', 'SD_R_60', 'SD_NIR_60', 'LW_60', 'GLCM1_60', 'Rect_60', 'GLCM2_60', 'Dens_60', 'Assym_60', 'NDVI_60', 'BordLngth_60', 'GLCM3_60', 'BrdIndx_80', 'Area_80', 'Round_80', 'Bright_80', 'Compact_80', 'ShpIndx_80', 'Mean_G_80', 'Mean_R_80', 'Mean_NIR_80', 'SD_G_80', 'SD_R_80', 'SD_NIR_80', 'LW_80', 'GLCM1_80', 'Rect_80', 'GLCM2_80', 'Dens_80', 'Assym_80', 'NDVI_80', 'BordLngth_80', 'GLCM3_80', 'BrdIndx_100', 'Area_100', 'Round_100', 'Bright_100', 'Compact_100', 'ShpIndx_100', 'Mean_G_100', 'Mean_R_100', 'Mean_NIR_100', 'SD_G_100', 'SD_R_100', 'SD_NIR_100', 'LW_100', 'GLCM1_100', 'Rect_100', 'GLCM2_100', 'Dens_100', 'Assym_100', 'NDVI_100', 'BordLngth_100', 'GLCM3_100', 'BrdIndx_120', 'Area_120', 'Round_120', 'Bright_120', 'Compact_120', 'ShpIndx_120', 'Mean_G_120', 'Mean_R_120', 'Mean_NIR_120', 'SD_G_120', 'SD_R_120', 'SD_NIR_120', 'LW_120', 'GLCM1_120', 'Rect_120', 'GLCM2_120', 'Dens_120', 'Assym_120', 'NDVI_120', 'BordLngth_120', 'GLCM3_120', 'BrdIndx_140', 'Area_140', 'Round_140', 'Bright_140', 'Compact_140', 'ShpIndx_140', 'Mean_G_140', 'Mean_R_140', 'Mean_NIR_140', 'SD_G_140', 'SD_R_140', 'SD_NIR_140', 'LW_140', 'GLCM1_140', 'Rect_140', 'GLCM2_140', 'Dens_140', 'Assym_140', 'NDVI_140', 'BordLngth_140', 'GLCM3_140']\n"
     ]
    }
   ],
   "source": [
    "# Select the variables that we be used \n",
    "target_column = \"class\" # The response variable that we will consider\n",
    "features_columns = list(ulc_train)\n",
    "features_columns.remove('class') # The predictors/features used to predict the target\n",
    "print(target_column)\n",
    "print(features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = ulc_train[features_columns], ulc_train[target_column]\n",
    "data_test, target_test = ulc_test[features_columns], ulc_test[target_column]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 1. Fit a random forest named *`rfc`* on the train set to explain the type of urban land cover (variable `class`) according to multi-scale spectral, size, shape, and texture information. More specifically, you will use the [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) class. Read carefully the documentation.\n",
    "\n",
    "*Indication: for the hyperparameters, use the values `n_estimators = 500` and `max_features= sqrt(d)` with `d` denoting the number of features, `oob_score=True`  and `random_state=0`.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before buiding `rfc` remind in the window below the meaning of`n_estimators` and `max_features`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer:............."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.12435565298214\n"
     ]
    }
   ],
   "source": [
    "n_features=sqrt(data.shape[1])\n",
    "print(n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_features=12, n_estimators=500, oob_score=True,\n",
       "                       random_state=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##------- Complete the command below by filling in the gaps '...'.-------##\n",
    "\n",
    "# Step 1: create the object rfc, it is a RandomForestClassifier object with n_estimators=500, max_features='auto' and random_state=0\n",
    "from math import sqrt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=500,max_features=\"auto\",oob_score=True,random_state=0)\n",
    "\n",
    "# Step 2: build the random forest on the train set by indicating the input data and the target variable \n",
    "rfc.fit(data,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution\n",
    "\n",
    "# Step 1: create the object rfc, it is a RandomForestClassifier object with n_estimators=500, max_features='auto' and random_state=0\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(n_estimators=500, max_features=12,oob_score=True,random_state=0)\n",
    "\n",
    "# Step 2: build the random forest on the train set by indicating the input data and the target variable \n",
    "rfc.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters of the forest:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 12,\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 500,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': True,\n",
      " 'random_state': 0,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##------- Complete the command below by filling in the gaps '...'.-------##\n",
    "\n",
    "# Step 3: look at the parameters used by your forest\n",
    "from pprint import pprint\n",
    "print('Parameters of the forest:\\n')\n",
    "pprint(rfc.get_params())\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the oob error and comment the result. What does it represent ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 12,\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 500,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': True,\n",
      " 'random_state': 0,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "##------- Complete the command below by filling in the gaps '...'.-------##\n",
    "# Step 4: print the oob_score (attributes of rfc named oob_score_)\n",
    "pprint(rfc.get_params('oob_score'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: print the oob_score (attributes of rfc named oob_score_)\n",
    "print('OOB error:'),\n",
    "print(rfc.oob_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning of the OOB error and result interpretation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Comment: ............."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2. Predict the class of each observation of the test sample by using the random forest `rfc`and display the confusion matrix. Comment it. How many observations are misclassified ? Compute the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------- Complete the command below by filling in the gaps '...'.-------##\n",
    "\n",
    "# Step 1: compute the predictions on the test set\n",
    "predictions_test = rfc.predict(.......) \n",
    "\n",
    "# Step 2: display the confusion matrix on the test set\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(....., .......)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=.....,display_labels=rfc.classes_)\n",
    "disp.plot() \n",
    "\n",
    "# Step 3: compute the accuracy on the test set\n",
    "accuracy = rfc.score(....,.....)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution\n",
    "\n",
    "# Step 1: compute the predictions\n",
    "predictions_test = rfc.predict(data_test) \n",
    "\n",
    "# Step 2: display the confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(target_test, predictions_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=rfc.classes_)\n",
    "disp.plot() \n",
    "\n",
    "# Step 3: compute the accuracy\n",
    "accuracy = rfc.score(data_test,target_test)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution\n",
    "\n",
    "# Step 1: compute the predictions\n",
    "predictions_test = rfc.predict(data_test) \n",
    "\n",
    "# Step 2: display the confusion matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(target_test, predictions_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=rfc.classes_)\n",
    "disp.plot() \n",
    "\n",
    "# Step 3: compute the accuracy\n",
    "accuracy = rfc.score(data_test,target_test)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: ........."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of misclassified observations in the test set:............"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3. We will now focus on the calibration of some RF parameters: `n_estimators` and `max_features`. To calibrate these parameters, we will used the OOB errors. The code below shows how the OOB error can be measured at the addition of each new tree during training. The resulting plot can be used to approximate a suitable value of `n_estimators` at which the OOB error stabilizes. Comment this plot. What value for `n_estimators` does it seem suitable ?\n",
    "\n",
    "*Indication: a suitable value for `n_estimators` is a value for which the oob error of the forest is stable.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "\n",
    "\n",
    "# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.\n",
    "error_rate = []\n",
    "\n",
    "# Range of `n_estimators` values to explore.\n",
    "min_estimators = 100\n",
    "max_estimators = 800\n",
    "step=5\n",
    "\n",
    "for i in range(min_estimators, max_estimators+1, step):\n",
    "    rf = RandomForestClassifier(warm_start=True, n_estimators=i, max_features='auto',random_state=RANDOM_STATE, oob_score=True)\n",
    "    rf.fit(data, target)\n",
    "\n",
    "    # Record the OOB error for each `n_estimators=i` setting.\n",
    "    oob_error = 1 - rf.oob_score_\n",
    "    error_rate.append(oob_error)\n",
    "  \n",
    "\n",
    "# Plot Generate the \"OOB error rate\" vs. \"n_estimators\" plot\n",
    "\n",
    "plt.plot(range(min_estimators, max_estimators +1, step), error_rate, label=\"OOB error rate\")\n",
    "\n",
    "plt.ylim(0, 1.5*max(error_rate)) \n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate vs. number of trees\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RANDOM_STATE = 0 # Note: if you modifiy the random stat, the results can be sligthly different\n",
    "\n",
    "\n",
    "# Map a classifier name to a list of (<n_estimators>, <error rate>) pairs.\n",
    "error_rate = []\n",
    "\n",
    "# Range of `n_estimators` values to explore.\n",
    "min_estimators = 100\n",
    "max_estimators = 800\n",
    "step=5\n",
    "\n",
    "for i in range(min_estimators, max_estimators+1, step):\n",
    "    rf = RandomForestClassifier(warm_start=True, n_estimators=i, max_features='auto',random_state=RANDOM_STATE, oob_score=True)\n",
    "    rf.fit(data, target)\n",
    "\n",
    "    # Record the OOB error for each `n_estimators=i` setting.\n",
    "    oob_error = 1 - rf.oob_score_\n",
    "    error_rate.append(oob_error)\n",
    "  \n",
    "\n",
    "# Plot Generate the \"OOB error rate\" vs. \"n_estimators\" plot\n",
    "\n",
    "plt.plot(range(min_estimators, max_estimators +1, step), error_rate, label=\"OOB error rate\")\n",
    "\n",
    "plt.ylim(0, 1.5*max(error_rate)) \n",
    "plt.xlim(min_estimators, max_estimators)\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"OOB error rate vs. number of trees\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment of the plot and choice of a suitable value for `n_estimators`: .............\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4. Now, we will repeat `B` times a `k`-fold cross validation with the function GridSearchCV to calibrate at the same time the parameters `n_estimators` and `max_features`. Complete the command below, comment the results and select suitable values for the parameters `n_estimators` and `max_features`.\n",
    "\n",
    "*Indications:*\n",
    "- *the values considers for `n_estimators` and `max_features` are `max_features = (0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9)` and `n_estimators=(400,600,800)`. The values (0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9) for `max_features` represent the proportions of selected features. See the documention of [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier) class.*\n",
    "- *we will repeat `B=10`times a k-fold crossvalidation with `k=3`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------- Complete the command below by filling in the gaps '...'.-------##\n",
    "\n",
    "# Step 1: create a grid with all the values that we will considers for the two paramters\n",
    "grid = {\n",
    "    'max_features':[..........], \n",
    "    'n_estimators':[...........]\n",
    "}\n",
    "\n",
    "# Step 2: use the grid to to search for the best couple of parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rf = RandomForestClassifier() # create the forest model to tune\n",
    "\n",
    "B=.......\n",
    "results_cv=pd.DataFrame()\n",
    "for i in range(B):\n",
    "    \n",
    "    rf_cv = GridSearchCV(estimator=rf,param_grid=grid, cv=......,n_jobs=-1)# Search the best values for the parameters using 3-fold cross validation, and use all available cores(n_jobs=-1)\n",
    "    rf_cv.fit(data, target) # Fit the CV search\n",
    "    if i==0: \n",
    "        results_cv=pd.DataFrame(rf_cv.cv_results_)[[\"params\",\"mean_test_score\",\"std_test_score\"]]\n",
    "    else:\n",
    "        results_cv[\"mean_test_score\"]=results_cv[\"mean_test_score\"]+pd.DataFrame(rf_cv.cv_results_)[\"mean_test_score\"]\n",
    "        results_cv[\"std_test_score\"]=results_cv[\"std_test_score\"]+pd.DataFrame(rf_cv.cv_results_)[\"std_test_score\"]  \n",
    "        \n",
    "        \n",
    "\n",
    "results_cv[\"mean_test_score\"]=results_cv[\"mean_test_score\"]/B\n",
    "results_cv[\"std_test_score\"]=results_cv[\"std_test_score\"]/B \n",
    "\n",
    "\n",
    "# Step 3: get the best parameters (with the higher performance)\n",
    "ind_best=results_cv[\"mean_test_score\"].idxmax()\n",
    "print(results_cv[\"params\"].iloc[ind_best])\n",
    "print(results_cv[\"mean_test_score\"].iloc[ind_best])\n",
    "print(results_cv[\"std_test_score\"].iloc[ind_best])\n",
    "print(results_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------- Complete the command below by filling in the gaps '...'.-------##\n",
    "\n",
    "# Step 1: create a grid with all the values that we will considers for the two paramters\n",
    "grid = {\n",
    "    'max_features':[..........], \n",
    "    'n_estimators':[...........]\n",
    "}\n",
    "\n",
    "# Step 2: use the grid to to search for the best couple of parameters\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "rf = RandomForestClassifier() # create the forest model to tune\n",
    "\n",
    "B=.......\n",
    "results_cv=pd.DataFrame()\n",
    "for i in range(B):\n",
    "    \n",
    "    rf_cv = GridSearchCV(estimator=rf,param_grid=grid, cv=......,n_jobs=-1)# Search the best values for the parameters using 3-fold cross validation, and use all available cores(n_jobs=-1)\n",
    "    rf_cv.fit(data, target) # Fit the CV search\n",
    "    if i==0: \n",
    "        results_cv=pd.DataFrame(rf_cv.cv_results_)[[\"params\",\"mean_test_score\",\"std_test_score\"]]\n",
    "    else:\n",
    "        results_cv[\"mean_test_score\"]=results_cv[\"mean_test_score\"]+pd.DataFrame(rf_cv.cv_results_)[\"mean_test_score\"]\n",
    "        results_cv[\"std_test_score\"]=results_cv[\"std_test_score\"]+pd.DataFrame(rf_cv.cv_results_)[\"std_test_score\"]  \n",
    "        \n",
    "        \n",
    "\n",
    "results_cv[\"mean_test_score\"]=results_cv[\"mean_test_score\"]/B\n",
    "results_cv[\"std_test_score\"]=results_cv[\"std_test_score\"]/B \n",
    "\n",
    "\n",
    "# Step 3: get the best parameters (with the higher performance)\n",
    "ind_best=results_cv[\"mean_test_score\"].idxmax()\n",
    "print(results_cv[\"params\"].iloc[ind_best])\n",
    "print(results_cv[\"mean_test_score\"].iloc[ind_best])\n",
    "print(results_cv[\"std_test_score\"].iloc[ind_best])\n",
    "print(results_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result interpretation and choice of tuned values for `n_estimators` and `max_features`: ........"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution for the interpretation and the selection of values for `n_estimators` and `max_features`: ......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5. Build the random forest `opt_rfc` by using the best values for the parameters `n_estimators` and `max_features`. Compute the accuracy on the test set and display the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------- Complete the command below by filling in the gaps '...'.-------##\n",
    "\n",
    "# Step 1: fit a random forest with the best values for parameters\n",
    "opt_rfc = RandomForestClassifier(n_estimators=...., max_features=....,oob_score=True,random_state=0)\n",
    "\n",
    "# Step 2: build the random forest on the train set by indicating the input data and the target variable \n",
    "opt_rfc.fit(...,.....)\n",
    "\n",
    "# Step 3: compute the accuracy and the confusion matrix\n",
    "predictions_test_2 = opt_rfc.predict(....) \n",
    "cm_2 = confusion_matrix(...., .....)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_2,display_labels=opt_rfc.classes_)\n",
    "disp.plot() \n",
    "\n",
    "# Step 4: compute the accuracy\n",
    "accuracy_2 = opt_rfc.score(....,.....)\n",
    "print(accuracy_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6. what value for`max_features` we have to choose if we want to apply the bagging algorithm with CART instead of a random forest ? Build this model and compute the prediction error of this model based on the test set. We will call this model $bag$.\n",
    "\n",
    "*Indication: use the value selected at `question 5`for the parameter `n_estimators`.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##------- Complete the command below by filling in the gaps '...'.-------##\n",
    "\n",
    "# Step 1: fit a a bagging model (use the best value for n_estimators)\n",
    "bag = RandomForestClassifier(n_estimators=...., max_features=....,oob_score=True,random_state=0)\n",
    "\n",
    "# Step 2: build the random forest on the train set by indicating the input data and the target variable \n",
    "bag.fit(...., ......)\n",
    "\n",
    "# Step 3: compute the prediction on the test set and the confusion matrix\n",
    "predictions_test_bag = bag.predict(......) \n",
    "cm_bag = confusion_matrix(.....,......)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_bag,display_labels=bag.classes_)\n",
    "disp.plot() \n",
    "\n",
    "# Step 4: compute the accuracy on the test set\n",
    "accuracy_bag = bag.score(....,.....)\n",
    "print(accuracy_bag)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 8. Compare your three models `opt_rfc`, `bag`and `rfc` using suitable performance criteria. What model do you choose and why ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your Answer: ........\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 9. The code below shows the boxplot of the mean decrease in accuracy (MDA) for the 15 features with the highest average MDA. The MDA of each of the 147 features has been independently computed `n__repeats =10` times on the test set for the random forest `opt_rfc` (at each run, another permutation is applied for the features). Comment the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "result = permutation_importance(opt_rfc, data_test, target_test, n_repeats=10, random_state=0, n_jobs=2)\n",
    "\n",
    "sorted_idx = result.importances_mean.argsort()\n",
    "invert_sorted_idx=sorted_idx[::-1][:14]# keep only the 15 features with the highest average MDA\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.boxplot(result.importances[invert_sorted_idx].T,\n",
    "           vert=False, labels=data_test.columns[invert_sorted_idx])\n",
    "ax.set_title(\"MDA computed on the test set for the 15 features with the highest average MDA (average MDA is displayed in orange\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments about the plot above: ......."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex 2: introduction to regression trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we consider the dataset named *srbct_data*. It is relative to small round blue cell tumors of childhood. This set is composed of :\n",
    "\n",
    "- a response factor of length 63, called class, indicating the class of each sample (4 classes in total).\n",
    "- 2308 predictors. Each predictor represents the expression of one gene. The features are correlated. \n",
    "\n",
    "More information about the data are available on https://www.rdocumentation.org/packages/plsgenomics/versions/1.5-2/topics/SRBCT \n",
    "\n",
    "The table named *genes_name* contains the names of the genes and a description for each gene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data \n",
    "import pandas as pd # data analysis\n",
    "srbct_data = pd.read_csv(\"cancer_data.csv\")\n",
    "genes_name = pd.read_csv(\"cancer_data_genes_names.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a look at the data \n",
    "srbct_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_name.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dimension and a brief statistics summary\n",
    "srbct_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a brief statistics summary\n",
    "srbct_data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Display a frequency table for the target variable named `class`.\n",
    "srbct_data[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the variables that we be used \n",
    "target_name = \"class\" # The response variable that we will consider\n",
    "features_names = list(srbct_data)\n",
    "features_names.remove('class') # The predictors/features used to predict the target\n",
    "#print(target_column)\n",
    "#print(features_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train (75% of data) and test dataset (25% of data)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y =  srbct_data[features_names], srbct_data[target_name]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0,test_size=0.25)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Questions:**\n",
    " - 1) Build a random forest on this dataset by using the [RandomForestRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor) class. Read carefully the documentation and use the default values for the RF parameters.\n",
    " - 2) Calibrate the two parameters `n_estimators` and `max_features` by using the same approach as in `Ex1 question 4`. Then, select values for `n_estimators` and `max_features`.\n",
    " - 3) Build a second random forest using the selected values for `n_estimators` and `max_features`.\n",
    " - 4) Because there are lots of features and they are correlated, use the MDA score to select a subset of only 20 variables (use the same approach as in `Ex1 question 9`). Justify your choice.\n",
    " - 5) Build a third random forest based only the selected subset of features.\n",
    " - 6) Compare the three models. What model do you select and why ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##---- Write your answer ----##\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
